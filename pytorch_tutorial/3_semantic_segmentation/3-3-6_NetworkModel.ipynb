{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3～3.6 네트워크 모델 만들기\n",
    "\n",
    "- 이 파일에서는 PSPNet의 네트워크 모델과 순전파 forward 함수를 작성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 PSPNet네트워크 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PSPNet, self).__init__()\n",
    "\n",
    "        # 파라미터 설정\n",
    "        block_config = [3, 4, 6, 3]  # resnet50\n",
    "        img_size = 475\n",
    "        img_size_8 = 60 \n",
    "\n",
    "        # 4개의 모듈을 구성하는 서브네트워크 준비\n",
    "        self.feature_conv = FeatureMap_convolution()\n",
    "        self.feature_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
    "        self.feature_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
    "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
    "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
    "\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n",
    "            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
    "\n",
    "        self.decode_feature = DecodePSPFeature(\n",
    "            height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "        self.aux = AuxiliaryPSPlayers(\n",
    "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.feature_res_1(x)\n",
    "        x = self.feature_res_2(x)\n",
    "        x = self.feature_dilated_res_1(x)\n",
    "\n",
    "        output_aux = self.aux(x)  # Feature 모듈의 중간을 Aux 모듈로\n",
    "\n",
    "        x = self.feature_dilated_res_2(x)\n",
    "\n",
    "        x = self.pyramid_pooling(x)\n",
    "        output = self.decode_feature(x)\n",
    "\n",
    "        return (output, output_aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Featureモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # inplase 설정에서 입력을 저장하지 않고 출력을 계산하고 메모리를 줄입니다.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        outputs = self.relu(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''구성할 네트워크 준비'''\n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "\n",
    "        # CONV Layer 1\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n",
    "        self.cbnr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # CONV Layer 2\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n",
    "        self.cbnr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # CONV Layer 3\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n",
    "        self.cbnr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # MaxPooling\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbnr_1(x)\n",
    "        x = self.cbnr_2(x)\n",
    "        x = self.cbnr_3(x)\n",
    "        outputs = self.maxpool(x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(ResidualBlockPSP, self).__init__()\n",
    "\n",
    "        # bottleNeckPSP\n",
    "        self.add_module(\n",
    "            \"block1\",\n",
    "            bottleNeckPSP(in_channels, mid_channels,\n",
    "                          out_channels, stride, dilation)\n",
    "        )\n",
    "\n",
    "        # bottleNeckIdentifyPSP 반복 준비\n",
    "        for i in range(n_blocks - 1):\n",
    "            self.add_module(\n",
    "                \"block\" + str(i+2),\n",
    "                bottleNeckIdentifyPSP(\n",
    "                    out_channels, mid_channels, stride, dilation)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        outputs = self.batchnorm(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(bottleNeckPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        # 건너뛰기 조인\n",
    "        self.cb_residual = conv2DBatchNorm(\n",
    "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = self.cb_residual(x)\n",
    "        return self.relu(conv + residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
    "        super(bottleNeckIdentifyPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = x\n",
    "        return self.relu(conv + residual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Pyramid Pooling모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, height, width):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "\n",
    "        # forward에서 사용할 이미지 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        # 각 컨벌루션 레이어의 출력 채널 수\n",
    "        out_channels = int(in_channels / len(pool_sizes))\n",
    "\n",
    "        # 각 컨벌루션 레이어 만들기\n",
    "        # pool_sizes: [6, 3, 2, 1]\n",
    "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
    "        self.cbr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
    "        self.cbr_4 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.cbr_1(self.avpool_1(x))\n",
    "        out1 = F.interpolate(out1, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out2 = self.cbr_2(self.avpool_2(x))\n",
    "        out2 = F.interpolate(out2, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out3 = self.cbr_3(self.avpool_3(x))\n",
    "        out3 = F.interpolate(out3, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out4 = self.cbr_4(self.avpool_4(x))\n",
    "        out4 = F.interpolate(out4, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        # 最終的に結合させる、dim=1でチャネル数の次元で結合\n",
    "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Decoder、AuxLoss모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self, height, width, n_classes):\n",
    "        super(DecodePSPFeature, self).__init__()\n",
    "\n",
    "        # forward에서 사용할 이미지 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryPSPlayers(nn.Module):\n",
    "    def __init__(self, in_channels, height, width, n_classes):\n",
    "        super(AuxiliaryPSPlayers, self).__init__()\n",
    "\n",
    "        # forward에서 사용할 이미지 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동작 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling(\n",
       "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
       "    (cbr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
       "    (cbr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
       "    (cbr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
       "    (cbr_4): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode_feature): DecodePSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPlayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 정의\n",
    "net = PSPNet(n_classes=21)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[ 5.7220e-01,  5.6368e-01,  5.5516e-01,  ...,  6.1565e-01,\n",
      "            6.2439e-01,  6.3314e-01],\n",
      "          [ 5.2103e-01,  5.1975e-01,  5.1846e-01,  ...,  6.1210e-01,\n",
      "            6.2256e-01,  6.3303e-01],\n",
      "          [ 4.6986e-01,  4.7581e-01,  4.8176e-01,  ...,  6.0855e-01,\n",
      "            6.2073e-01,  6.3292e-01],\n",
      "          ...,\n",
      "          [ 3.0546e-01,  3.0324e-01,  3.0102e-01,  ...,  4.4424e-01,\n",
      "            4.6409e-01,  4.8394e-01],\n",
      "          [ 3.6091e-01,  3.6041e-01,  3.5990e-01,  ...,  4.5358e-01,\n",
      "            4.6735e-01,  4.8112e-01],\n",
      "          [ 4.1637e-01,  4.1758e-01,  4.1879e-01,  ...,  4.6293e-01,\n",
      "            4.7061e-01,  4.7830e-01]],\n",
      "\n",
      "         [[-9.8863e-01, -9.1336e-01, -8.3809e-01,  ..., -6.2426e-01,\n",
      "           -5.6834e-01, -5.1243e-01],\n",
      "          [-9.7684e-01, -9.0127e-01, -8.2569e-01,  ..., -6.2517e-01,\n",
      "           -5.8006e-01, -5.3496e-01],\n",
      "          [-9.6505e-01, -8.8917e-01, -8.1329e-01,  ..., -6.2609e-01,\n",
      "           -5.9178e-01, -5.5748e-01],\n",
      "          ...,\n",
      "          [-2.7294e-01, -2.9138e-01, -3.0983e-01,  ..., -7.6238e-01,\n",
      "           -7.4594e-01, -7.2950e-01],\n",
      "          [-2.7724e-01, -2.8524e-01, -2.9325e-01,  ..., -7.2655e-01,\n",
      "           -7.0676e-01, -6.8696e-01],\n",
      "          [-2.8153e-01, -2.7910e-01, -2.7667e-01,  ..., -6.9073e-01,\n",
      "           -6.6757e-01, -6.4442e-01]],\n",
      "\n",
      "         [[ 7.5783e-01,  7.6731e-01,  7.7679e-01,  ...,  4.8783e-01,\n",
      "            4.2845e-01,  3.6907e-01],\n",
      "          [ 7.3994e-01,  7.4206e-01,  7.4419e-01,  ...,  4.7234e-01,\n",
      "            4.2701e-01,  3.8168e-01],\n",
      "          [ 7.2205e-01,  7.1682e-01,  7.1159e-01,  ...,  4.5685e-01,\n",
      "            4.2557e-01,  3.9429e-01],\n",
      "          ...,\n",
      "          [ 4.0844e-01,  4.4388e-01,  4.7931e-01,  ...,  3.4494e-01,\n",
      "            3.5600e-01,  3.6706e-01],\n",
      "          [ 4.0425e-01,  4.4355e-01,  4.8285e-01,  ...,  3.4283e-01,\n",
      "            3.4930e-01,  3.5577e-01],\n",
      "          [ 4.0005e-01,  4.4323e-01,  4.8640e-01,  ...,  3.4073e-01,\n",
      "            3.4260e-01,  3.4447e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6358e-01, -1.1619e-01, -6.8798e-02,  ...,  3.5794e-01,\n",
      "            4.0337e-01,  4.4879e-01],\n",
      "          [-1.2320e-01, -7.2908e-02, -2.2615e-02,  ...,  3.8619e-01,\n",
      "            4.3370e-01,  4.8121e-01],\n",
      "          [-8.2824e-02, -2.9628e-02,  2.3567e-02,  ...,  4.1443e-01,\n",
      "            4.6403e-01,  5.1363e-01],\n",
      "          ...,\n",
      "          [ 4.6776e-01,  4.7544e-01,  4.8312e-01,  ...,  2.8026e-01,\n",
      "            2.2571e-01,  1.7117e-01],\n",
      "          [ 4.9961e-01,  5.0618e-01,  5.1275e-01,  ...,  2.4985e-01,\n",
      "            1.9260e-01,  1.3535e-01],\n",
      "          [ 5.3147e-01,  5.3692e-01,  5.4238e-01,  ...,  2.1943e-01,\n",
      "            1.5948e-01,  9.9529e-02]],\n",
      "\n",
      "         [[-4.5849e-01, -4.9118e-01, -5.2387e-01,  ..., -2.1087e-01,\n",
      "           -2.0931e-01, -2.0775e-01],\n",
      "          [-4.4226e-01, -4.6386e-01, -4.8546e-01,  ..., -1.9891e-01,\n",
      "           -1.9479e-01, -1.9068e-01],\n",
      "          [-4.2602e-01, -4.3654e-01, -4.4706e-01,  ..., -1.8694e-01,\n",
      "           -1.8028e-01, -1.7361e-01],\n",
      "          ...,\n",
      "          [-3.2338e-01, -3.0764e-01, -2.9190e-01,  ..., -4.1350e-01,\n",
      "           -3.7853e-01, -3.4356e-01],\n",
      "          [-3.0453e-01, -2.8677e-01, -2.6901e-01,  ..., -3.9955e-01,\n",
      "           -3.6168e-01, -3.2381e-01],\n",
      "          [-2.8568e-01, -2.6590e-01, -2.4611e-01,  ..., -3.8560e-01,\n",
      "           -3.4483e-01, -3.0405e-01]],\n",
      "\n",
      "         [[-8.7808e-01, -8.6923e-01, -8.6038e-01,  ..., -4.8436e-01,\n",
      "           -5.0672e-01, -5.2908e-01],\n",
      "          [-7.5195e-01, -7.4468e-01, -7.3741e-01,  ..., -4.1308e-01,\n",
      "           -4.3577e-01, -4.5847e-01],\n",
      "          [-6.2582e-01, -6.2013e-01, -6.1444e-01,  ..., -3.4179e-01,\n",
      "           -3.6483e-01, -3.8787e-01],\n",
      "          ...,\n",
      "          [ 1.2578e-01,  1.1201e-01,  9.8236e-02,  ..., -5.7956e-01,\n",
      "           -6.4130e-01, -7.0304e-01],\n",
      "          [ 1.2710e-01,  1.0706e-01,  8.7012e-02,  ..., -6.5170e-01,\n",
      "           -7.1082e-01, -7.6995e-01],\n",
      "          [ 1.2842e-01,  1.0210e-01,  7.5788e-02,  ..., -7.2383e-01,\n",
      "           -7.8034e-01, -8.3685e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8555e-01,  2.0095e-01,  2.1634e-01,  ...,  1.0312e-01,\n",
      "            1.2265e-01,  1.4218e-01],\n",
      "          [ 1.9213e-01,  2.0612e-01,  2.2011e-01,  ...,  1.5960e-01,\n",
      "            1.8623e-01,  2.1286e-01],\n",
      "          [ 1.9871e-01,  2.1129e-01,  2.2387e-01,  ...,  2.1609e-01,\n",
      "            2.4981e-01,  2.8353e-01],\n",
      "          ...,\n",
      "          [ 4.5447e-02,  3.9122e-02,  3.2797e-02,  ...,  3.9735e-01,\n",
      "            4.4063e-01,  4.8392e-01],\n",
      "          [ 9.8835e-03,  1.2968e-02,  1.6052e-02,  ...,  3.5042e-01,\n",
      "            3.9658e-01,  4.4274e-01],\n",
      "          [-2.5680e-02, -1.3187e-02, -6.9386e-04,  ...,  3.0348e-01,\n",
      "            3.5252e-01,  4.0156e-01]],\n",
      "\n",
      "         [[-9.5084e-01, -8.5677e-01, -7.6270e-01,  ..., -5.8198e-01,\n",
      "           -5.8637e-01, -5.9075e-01],\n",
      "          [-9.5752e-01, -8.7307e-01, -7.8861e-01,  ..., -5.7914e-01,\n",
      "           -5.7183e-01, -5.6452e-01],\n",
      "          [-9.6421e-01, -8.8937e-01, -8.1453e-01,  ..., -5.7630e-01,\n",
      "           -5.5730e-01, -5.3830e-01],\n",
      "          ...,\n",
      "          [-7.6682e-01, -7.1514e-01, -6.6345e-01,  ..., -5.3967e-01,\n",
      "           -5.3544e-01, -5.3121e-01],\n",
      "          [-7.6488e-01, -7.0951e-01, -6.5415e-01,  ..., -5.6337e-01,\n",
      "           -5.6385e-01, -5.6433e-01],\n",
      "          [-7.6294e-01, -7.0389e-01, -6.4485e-01,  ..., -5.8707e-01,\n",
      "           -5.9226e-01, -5.9745e-01]],\n",
      "\n",
      "         [[ 3.3253e-01,  3.7276e-01,  4.1299e-01,  ...,  2.3983e-01,\n",
      "            2.5983e-01,  2.7982e-01],\n",
      "          [ 3.4188e-01,  3.7441e-01,  4.0693e-01,  ...,  2.4833e-01,\n",
      "            2.6093e-01,  2.7353e-01],\n",
      "          [ 3.5123e-01,  3.7605e-01,  4.0087e-01,  ...,  2.5684e-01,\n",
      "            2.6204e-01,  2.6723e-01],\n",
      "          ...,\n",
      "          [ 1.1592e-01,  1.5689e-01,  1.9786e-01,  ...,  1.1540e-01,\n",
      "            1.9073e-01,  2.6605e-01],\n",
      "          [ 8.2599e-02,  1.2519e-01,  1.6778e-01,  ...,  8.6838e-02,\n",
      "            1.7430e-01,  2.6176e-01],\n",
      "          [ 4.9277e-02,  9.3487e-02,  1.3770e-01,  ...,  5.8270e-02,\n",
      "            1.5787e-01,  2.5747e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4217e-01,  3.7370e-01,  3.0523e-01,  ...,  3.6772e-01,\n",
      "            3.9572e-01,  4.2371e-01],\n",
      "          [ 3.6749e-01,  3.1168e-01,  2.5586e-01,  ...,  3.6637e-01,\n",
      "            3.9183e-01,  4.1729e-01],\n",
      "          [ 2.9282e-01,  2.4966e-01,  2.0649e-01,  ...,  3.6501e-01,\n",
      "            3.8794e-01,  4.1087e-01],\n",
      "          ...,\n",
      "          [ 3.9517e-01,  4.2207e-01,  4.4897e-01,  ...,  2.4564e-01,\n",
      "            2.5527e-01,  2.6490e-01],\n",
      "          [ 3.9596e-01,  4.3643e-01,  4.7691e-01,  ...,  2.5039e-01,\n",
      "            2.6343e-01,  2.7647e-01],\n",
      "          [ 3.9675e-01,  4.5080e-01,  5.0484e-01,  ...,  2.5513e-01,\n",
      "            2.7158e-01,  2.8803e-01]],\n",
      "\n",
      "         [[ 1.6372e-02,  2.2204e-03, -1.1931e-02,  ..., -3.4651e-02,\n",
      "            6.2313e-03,  4.7114e-02],\n",
      "          [ 5.6053e-02,  5.0072e-02,  4.4092e-02,  ..., -3.3385e-02,\n",
      "           -8.2239e-04,  3.1740e-02],\n",
      "          [ 9.5733e-02,  9.7924e-02,  1.0011e-01,  ..., -3.2119e-02,\n",
      "           -7.8761e-03,  1.6367e-02],\n",
      "          ...,\n",
      "          [ 1.7419e-01,  1.3135e-01,  8.8514e-02,  ...,  4.6744e-02,\n",
      "            7.3346e-02,  9.9947e-02],\n",
      "          [ 1.9522e-01,  1.4920e-01,  1.0318e-01,  ...,  9.1673e-02,\n",
      "            1.1514e-01,  1.3860e-01],\n",
      "          [ 2.1625e-01,  1.6705e-01,  1.1785e-01,  ...,  1.3660e-01,\n",
      "            1.5693e-01,  1.7725e-01]],\n",
      "\n",
      "         [[-5.5818e-01, -6.0102e-01, -6.4387e-01,  ..., -1.4061e-01,\n",
      "           -9.0707e-02, -4.0807e-02],\n",
      "          [-5.1951e-01, -5.5307e-01, -5.8663e-01,  ..., -1.6275e-01,\n",
      "           -1.1895e-01, -7.5159e-02],\n",
      "          [-4.8085e-01, -5.0512e-01, -5.2939e-01,  ..., -1.8489e-01,\n",
      "           -1.4720e-01, -1.0951e-01],\n",
      "          ...,\n",
      "          [ 1.6079e-01,  1.8139e-01,  2.0199e-01,  ..., -4.2616e-01,\n",
      "           -4.8040e-01, -5.3464e-01],\n",
      "          [ 1.7740e-01,  2.0060e-01,  2.2380e-01,  ..., -4.5444e-01,\n",
      "           -5.0178e-01, -5.4912e-01],\n",
      "          [ 1.9400e-01,  2.1980e-01,  2.4561e-01,  ..., -4.8272e-01,\n",
      "           -5.2317e-01, -5.6361e-01]]]], grad_fn=<UpsampleBilinear2DBackward1>), tensor([[[[ 3.1200e-01,  3.0128e-01,  2.9055e-01,  ...,  1.9137e-01,\n",
      "            1.4890e-01,  1.0644e-01],\n",
      "          [ 2.8377e-01,  2.7957e-01,  2.7537e-01,  ...,  1.8316e-01,\n",
      "            1.4575e-01,  1.0835e-01],\n",
      "          [ 2.5554e-01,  2.5787e-01,  2.6019e-01,  ...,  1.7495e-01,\n",
      "            1.4260e-01,  1.1026e-01],\n",
      "          ...,\n",
      "          [ 3.5243e-02,  2.7971e-02,  2.0699e-02,  ..., -9.8309e-02,\n",
      "           -9.4501e-02, -9.0693e-02],\n",
      "          [-8.9076e-03, -8.6237e-03, -8.3398e-03,  ..., -1.0575e-01,\n",
      "           -1.0054e-01, -9.5330e-02],\n",
      "          [-5.3058e-02, -4.5218e-02, -3.7378e-02,  ..., -1.1319e-01,\n",
      "           -1.0658e-01, -9.9966e-02]],\n",
      "\n",
      "         [[ 1.2328e-01,  6.8344e-02,  1.3406e-02,  ..., -2.1100e-02,\n",
      "           -2.3683e-02, -2.6265e-02],\n",
      "          [ 8.7864e-02,  4.5372e-02,  2.8793e-03,  ..., -8.6949e-03,\n",
      "           -1.3557e-02, -1.8419e-02],\n",
      "          [ 5.2447e-02,  2.2400e-02, -7.6475e-03,  ...,  3.7103e-03,\n",
      "           -3.4309e-03, -1.0572e-02],\n",
      "          ...,\n",
      "          [-1.2128e-01, -1.0025e-01, -7.9223e-02,  ...,  1.8396e-02,\n",
      "            3.7171e-02,  5.5946e-02],\n",
      "          [-1.0845e-01, -8.5750e-02, -6.3051e-02,  ...,  2.4930e-02,\n",
      "            3.9457e-02,  5.3984e-02],\n",
      "          [-9.5619e-02, -7.1249e-02, -4.6879e-02,  ...,  3.1465e-02,\n",
      "            4.1744e-02,  5.2023e-02]],\n",
      "\n",
      "         [[-9.1598e-02, -1.2027e-01, -1.4895e-01,  ..., -4.2395e-01,\n",
      "           -4.1731e-01, -4.1067e-01],\n",
      "          [-1.6134e-01, -1.8167e-01, -2.0200e-01,  ..., -4.3112e-01,\n",
      "           -4.2237e-01, -4.1363e-01],\n",
      "          [-2.3107e-01, -2.4306e-01, -2.5505e-01,  ..., -4.3829e-01,\n",
      "           -4.2743e-01, -4.1658e-01],\n",
      "          ...,\n",
      "          [-8.6315e-02, -1.1989e-01, -1.5346e-01,  ..., -2.2654e-01,\n",
      "           -2.2627e-01, -2.2599e-01],\n",
      "          [-4.4735e-02, -9.0406e-02, -1.3608e-01,  ..., -2.0531e-01,\n",
      "           -2.0550e-01, -2.0570e-01],\n",
      "          [-3.1545e-03, -6.0926e-02, -1.1870e-01,  ..., -1.8408e-01,\n",
      "           -1.8474e-01, -1.8541e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0793e-01, -4.9924e-01, -4.9055e-01,  ..., -6.3569e-01,\n",
      "           -6.2213e-01, -6.0856e-01],\n",
      "          [-5.2623e-01, -5.2164e-01, -5.1705e-01,  ..., -6.3719e-01,\n",
      "           -6.2380e-01, -6.1040e-01],\n",
      "          [-5.4453e-01, -5.4405e-01, -5.4356e-01,  ..., -6.3869e-01,\n",
      "           -6.2547e-01, -6.1224e-01],\n",
      "          ...,\n",
      "          [-1.3624e-01, -1.5587e-01, -1.7549e-01,  ..., -4.4766e-01,\n",
      "           -4.6245e-01, -4.7725e-01],\n",
      "          [-8.7689e-02, -1.0630e-01, -1.2491e-01,  ..., -4.7613e-01,\n",
      "           -4.9859e-01, -5.2105e-01],\n",
      "          [-3.9135e-02, -5.6729e-02, -7.4323e-02,  ..., -5.0459e-01,\n",
      "           -5.3472e-01, -5.6484e-01]],\n",
      "\n",
      "         [[-6.5244e-01, -5.1310e-01, -3.7377e-01,  ..., -1.8615e-02,\n",
      "           -2.5992e-03,  1.3417e-02],\n",
      "          [-5.7308e-01, -4.4549e-01, -3.1790e-01,  ..., -4.5105e-02,\n",
      "           -3.2010e-02, -1.8916e-02],\n",
      "          [-4.9373e-01, -3.7788e-01, -2.6203e-01,  ..., -7.1595e-02,\n",
      "           -6.1422e-02, -5.1248e-02],\n",
      "          ...,\n",
      "          [-3.5988e-01, -2.9672e-01, -2.3357e-01,  ..., -3.2653e-01,\n",
      "           -3.5159e-01, -3.7664e-01],\n",
      "          [-3.7845e-01, -3.2141e-01, -2.6438e-01,  ..., -3.8045e-01,\n",
      "           -4.1135e-01, -4.4225e-01],\n",
      "          [-3.9703e-01, -3.4611e-01, -2.9518e-01,  ..., -4.3437e-01,\n",
      "           -4.7112e-01, -5.0786e-01]],\n",
      "\n",
      "         [[-7.6637e-02, -3.2217e-02,  1.2204e-02,  ...,  1.6837e-02,\n",
      "           -1.5705e-02, -4.8246e-02],\n",
      "          [-3.8104e-02, -4.1579e-03,  2.9788e-02,  ..., -2.1142e-02,\n",
      "           -5.5123e-02, -8.9105e-02],\n",
      "          [ 4.2901e-04,  2.3901e-02,  4.7372e-02,  ..., -5.9121e-02,\n",
      "           -9.4542e-02, -1.2996e-01],\n",
      "          ...,\n",
      "          [ 7.9027e-02,  5.9247e-02,  3.9466e-02,  ...,  1.0657e-01,\n",
      "            7.2283e-02,  3.7999e-02],\n",
      "          [ 9.1553e-02,  7.2985e-02,  5.4417e-02,  ...,  1.0289e-01,\n",
      "            6.9677e-02,  3.6460e-02],\n",
      "          [ 1.0408e-01,  8.6723e-02,  6.9369e-02,  ...,  9.9220e-02,\n",
      "            6.7070e-02,  3.4921e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3192e-01,  1.4241e-01,  1.5291e-01,  ...,  4.7403e-02,\n",
      "            4.2294e-02,  3.7185e-02],\n",
      "          [ 1.4571e-01,  1.5809e-01,  1.7047e-01,  ...,  5.3478e-02,\n",
      "            4.4090e-02,  3.4702e-02],\n",
      "          [ 1.5950e-01,  1.7376e-01,  1.8803e-01,  ...,  5.9552e-02,\n",
      "            4.5886e-02,  3.2219e-02],\n",
      "          ...,\n",
      "          [ 1.0582e-01,  1.6705e-01,  2.2828e-01,  ...,  3.3222e-02,\n",
      "           -1.0629e-02, -5.4480e-02],\n",
      "          [ 1.3273e-01,  1.9399e-01,  2.5526e-01,  ...,  3.0171e-02,\n",
      "           -2.0964e-02, -7.2099e-02],\n",
      "          [ 1.5964e-01,  2.2094e-01,  2.8223e-01,  ...,  2.7120e-02,\n",
      "           -3.1299e-02, -8.9718e-02]],\n",
      "\n",
      "         [[ 2.0953e-01,  1.6179e-01,  1.1406e-01,  ...,  4.0244e-02,\n",
      "            4.7654e-02,  5.5064e-02],\n",
      "          [ 1.8441e-01,  1.4298e-01,  1.0154e-01,  ...,  5.1291e-02,\n",
      "            5.6051e-02,  6.0811e-02],\n",
      "          [ 1.5929e-01,  1.2416e-01,  8.9028e-02,  ...,  6.2337e-02,\n",
      "            6.4448e-02,  6.6558e-02],\n",
      "          ...,\n",
      "          [ 1.8212e-01,  1.9337e-01,  2.0462e-01,  ...,  3.6395e-01,\n",
      "            3.6343e-01,  3.6291e-01],\n",
      "          [ 1.8784e-01,  2.0050e-01,  2.1317e-01,  ...,  4.3899e-01,\n",
      "            4.4399e-01,  4.4899e-01],\n",
      "          [ 1.9356e-01,  2.0764e-01,  2.2173e-01,  ...,  5.1402e-01,\n",
      "            5.2454e-01,  5.3506e-01]],\n",
      "\n",
      "         [[-1.7479e-02, -5.6319e-02, -9.5160e-02,  ..., -6.7007e-01,\n",
      "           -6.6610e-01, -6.6212e-01],\n",
      "          [-6.1682e-02, -9.8879e-02, -1.3608e-01,  ..., -5.8696e-01,\n",
      "           -5.7789e-01, -5.6882e-01],\n",
      "          [-1.0588e-01, -1.4144e-01, -1.7699e-01,  ..., -5.0384e-01,\n",
      "           -4.8968e-01, -4.7552e-01],\n",
      "          ...,\n",
      "          [ 1.3121e-01,  1.4572e-01,  1.6022e-01,  ..., -2.9398e-01,\n",
      "           -2.9486e-01, -2.9573e-01],\n",
      "          [ 1.5077e-01,  1.6389e-01,  1.7701e-01,  ..., -2.5963e-01,\n",
      "           -2.5177e-01, -2.4390e-01],\n",
      "          [ 1.7034e-01,  1.8207e-01,  1.9380e-01,  ..., -2.2528e-01,\n",
      "           -2.0867e-01, -1.9207e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7749e-01, -3.6015e-01, -3.4282e-01,  ..., -3.6787e-01,\n",
      "           -3.2889e-01, -2.8991e-01],\n",
      "          [-3.5035e-01, -3.3420e-01, -3.1805e-01,  ..., -3.7333e-01,\n",
      "           -3.3956e-01, -3.0578e-01],\n",
      "          [-3.2322e-01, -3.0825e-01, -2.9328e-01,  ..., -3.7880e-01,\n",
      "           -3.5023e-01, -3.2166e-01],\n",
      "          ...,\n",
      "          [-4.0585e-01, -4.1296e-01, -4.2007e-01,  ..., -4.4760e-01,\n",
      "           -4.6625e-01, -4.8489e-01],\n",
      "          [-4.3719e-01, -4.3700e-01, -4.3682e-01,  ..., -4.0004e-01,\n",
      "           -4.1747e-01, -4.3489e-01],\n",
      "          [-4.6852e-01, -4.6104e-01, -4.5357e-01,  ..., -3.5248e-01,\n",
      "           -3.6868e-01, -3.8489e-01]],\n",
      "\n",
      "         [[-2.2488e-01, -1.8470e-01, -1.4452e-01,  ...,  7.9489e-02,\n",
      "            7.0654e-02,  6.1818e-02],\n",
      "          [-2.1679e-01, -1.6945e-01, -1.2211e-01,  ...,  9.2107e-02,\n",
      "            7.3585e-02,  5.5063e-02],\n",
      "          [-2.0869e-01, -1.5420e-01, -9.9705e-02,  ...,  1.0472e-01,\n",
      "            7.6517e-02,  4.8309e-02],\n",
      "          ...,\n",
      "          [-3.6968e-01, -2.9961e-01, -2.2953e-01,  ...,  2.1912e-01,\n",
      "            1.9836e-01,  1.7759e-01],\n",
      "          [-4.4578e-01, -3.7713e-01, -3.0847e-01,  ...,  1.5412e-01,\n",
      "            1.2783e-01,  1.0155e-01],\n",
      "          [-5.2187e-01, -4.5464e-01, -3.8742e-01,  ...,  8.9115e-02,\n",
      "            5.7310e-02,  2.5505e-02]],\n",
      "\n",
      "         [[ 1.3886e-01,  1.4620e-01,  1.5354e-01,  ...,  8.5311e-02,\n",
      "            4.0146e-02, -5.0184e-03],\n",
      "          [ 1.7417e-01,  1.8139e-01,  1.8862e-01,  ...,  5.4884e-02,\n",
      "            3.5456e-03, -4.7793e-02],\n",
      "          [ 2.0948e-01,  2.1658e-01,  2.2369e-01,  ...,  2.4456e-02,\n",
      "           -3.3055e-02, -9.0567e-02],\n",
      "          ...,\n",
      "          [ 3.2280e-01,  2.6998e-01,  2.1716e-01,  ..., -1.5800e-01,\n",
      "           -1.1313e-01, -6.8266e-02],\n",
      "          [ 3.1400e-01,  2.5872e-01,  2.0343e-01,  ..., -1.5730e-01,\n",
      "           -1.0193e-01, -4.6557e-02],\n",
      "          [ 3.0520e-01,  2.4745e-01,  1.8971e-01,  ..., -1.5659e-01,\n",
      "           -9.0721e-02, -2.4848e-02]]]], grad_fn=<UpsampleBilinear2DBackward1>))\n"
     ]
    }
   ],
   "source": [
    "# 더미 데이터 만들기\n",
    "batch_size = 2\n",
    "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
    "\n",
    "# 계산하다\n",
    "outputs = net(dummy_img)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('3.9.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b5a2607b268c83f9234f72a8efd9e01dc35cb6c7bfdbeb288788ddada4de7aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
