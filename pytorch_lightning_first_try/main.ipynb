{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Package 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch<1.9,>=1.6 (from versions: 1.9.0, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch<1.9,>=1.6\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from pytorch-lightning) (4.3.0)\n",
      "Requirement already satisfied: torch>=1.9.* in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from pytorch-lightning) (1.12.1)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Using cached fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from pytorch-lightning) (1.23.3)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
      "Collecting PyYAML>=5.4\n",
      "  Using cached PyYAML-6.0.tar.gz (124 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.3-cp38-cp38-macosx_11_0_arm64.whl (337 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.36.2)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.5-py2.py3-none-any.whl (162 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.11.1-py2.py3-none-any.whl (167 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (57.0.0)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.49.1.tar.gz (22.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp38-cp38-macosx_11_0_arm64.whl (35 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp38-cp38-macosx_11_0_arm64.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting attrs>=17.3.0\n",
      "  Using cached attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.1-cp38-cp38-macosx_10_9_universal2.whl (17 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: PyYAML, grpcio\n",
      "  Building wheel for PyYAML (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-6.0-cp38-cp38-macosx_10_14_arm64.whl size=45338 sha256=928c54c08cec6063f2f3b6a173fb1ea0b53b410eec1a558501dc0e58d613d07a\n",
      "  Stored in directory: /Users/joonhwi/Library/Caches/pip/wheels/52/84/66/50912fd7bf1639a31758e40bd4312602e104a8eca1e0da9645\n",
      "  Building wheel for grpcio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpcio: filename=grpcio-1.49.1-cp38-cp38-macosx_10_14_arm64.whl size=7903788 sha256=b09f4efa7ec1e359ee9ae7e5577e4539b2f8281bfe3b2b8026dc389c3159d88c\n",
      "  Stored in directory: /Users/joonhwi/Library/Caches/pip/wheels/ae/75/9b/1cfee21306a9993817964b0c777cbedf8a42342254986cd0e9\n",
      "Successfully built PyYAML grpcio\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, zipp, urllib3, tqdm, tensorboard-data-server, rsa, PyYAML, pyDeprecate, pyasn1-modules, protobuf, oauthlib, multidict, MarkupSafe, idna, grpcio, fsspec, frozenlist, charset-normalizer, certifi, cachetools, attrs, async-timeout, absl-py, yarl, werkzeug, torchmetrics, requests, importlib-metadata, google-auth, aiosignal, requests-oauthlib, markdown, aiohttp, google-auth-oauthlib, tensorboard, pytorch-lightning\n",
      "Successfully installed MarkupSafe-2.1.1 PyYAML-6.0 absl-py-1.2.0 aiohttp-3.8.3 aiosignal-1.2.0 async-timeout-4.0.2 attrs-22.1.0 cachetools-5.2.0 certifi-2022.9.24 charset-normalizer-2.1.1 frozenlist-1.3.1 fsspec-2022.8.2 google-auth-2.11.1 google-auth-oauthlib-0.4.6 grpcio-1.49.1 idna-3.4 importlib-metadata-4.12.0 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.1 protobuf-3.19.5 pyDeprecate-0.3.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-1.7.7 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torchmetrics-0.9.3 tqdm-4.64.1 urllib3-1.26.12 werkzeug-2.2.2 yarl-1.8.1 zipp-3.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet \"pandas\" \"torch>=1.6, <1.9\" \"torchvision\" \"ipython[notebook]\" \"seaborn\" \"pytorch-lightning>=1.4\" \"torchmetrics>=0.6\" \"lightning-bolts\"\n",
    "! pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install seaborn\n",
    "#! pip install torchvision\n",
    "#! pip install lightning-bolts\n",
    "#! pip install pytorch_lightning\n",
    "# install pytorch lighting\n",
    "! pip install pytorch-lightning --quiet\n",
    "# install weights and biases\n",
    "! pip install wandb --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pytorch_lightning as pl\n",
    "# your favorite machine learning tracking tool\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 데이터 모듈 정의하기\n",
    "\n",
    "cifar 10 데이터셋을 사용합니다.\n",
    "\n",
    "cifar 10 데이터 셋은 LightningDataModule의 서브클래스이므로, 상속받아 메서드를 구현한다.\n",
    "\n",
    "공식 doc 참고하기 : https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html\n",
    "\n",
    "### 메서드 간략 설명\n",
    "    prepare_data\n",
    "GPU 하나에서 한 번만 호출된다. 일반적으로 아래의 데이터 다운로드 단계와 같다.\n",
    "\n",
    "    setup\n",
    "각각의 GPU에서 개별적으로 호출되며 fit 또는 test단계일 경우 정의할 스테이지를 받아온다.\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader\n",
    "각각의 데이터 세트를 로드한다.\n",
    "\n",
    "### Notes\n",
    "- random_split : training-validation split구분을 용이하게 한다. 전체 데이터셋에 적용된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, data_dir: str = './'):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            #텐서화 및 정규화\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        # 클래스 수 정의\n",
    "        self.num_classes = 10\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            #cifar 데이터 받아와서 경로, transform, train, 등등 설정하기 \n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logger 정의하기\n",
    "\n",
    "epoch이 끝날 때마다 성능 로그를 남긴다. \n",
    "\n",
    "## Notes\n",
    "    pytorch_lightning.callbacks.Callback\n",
    "\n",
    "공식 docs 보기 : https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html\n",
    "\n",
    "프로젝트 전체에서 재사용할 수 있는 독립형 프로그램을 뜻한다.\n",
    "\n",
    "예를 들어, 학습중\n",
    "\n",
    "    on_validation_epoch_end\n",
    "\n",
    "메서드가 수행되면 callback hook 이 수행되어 아래의 코드가 수행된다.\n",
    "\n",
    "다시말해 validation epoch이 종료될 때, 로그를 남기는 코드가 수행되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePredictionLogger(pl.callbacks.Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Bring the tensors to CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Get model prediction\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 정의하기\n",
    "\n",
    "LightningModule은 모델이 아닌 시스템을 정의하기 때문에, 모델을 단일 클래스로 독립화시켜야한다.\n",
    "\n",
    "기존의 Pytorch 코드를 5개의 섹션으로 구분하여 넣어주면 된다.\n",
    "- Computations (__init__).\n",
    "\n",
    "- Train loop (training_step)\n",
    "\n",
    "- Validation loop (validation_step)\n",
    "\n",
    "- Test loop (test_step)\n",
    "\n",
    "- Optimizers (configure_optimizers)\n",
    "\n",
    "### 메서드 간략 설명\n",
    "pytorch_lightning.LightningModule은 모델의 아키텍처와 forward 전달 방식을 상속받아 구현할 수 있게 해놨다.\n",
    "\n",
    "#### 1. init 메서드\n",
    "\n",
    "init에서 모델에 필요한 하이퍼 파라미터를 전달한다.\n",
    "\n",
    "    save_parameters\n",
    "\n",
    "를 call 함으로써 init에 있는 모든 값을 check point에 저장하도록 요청할 수 있다.\n",
    "\n",
    ". . .\n",
    "\n",
    "\n",
    "    _get_conv_output과 _forward_features\n",
    "\n",
    "메서드는 convolutional block의 텐서 사이즈를 자동으로 계산하는데 사용한다. \n",
    "\n",
    ". . .\n",
    "\n",
    "    forward\n",
    "일단 파이토치 코드와 비슷하나, 라이트닝에서는 오직 inference action을 위해서만 사용된다. training_step은 학습 loop를 정의한다.\n",
    "\n",
    "\n",
    "#### 2. Training step 메서드\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, input_shape, num_classes, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 1)\n",
    "\n",
    "        self.pool1 = torch.nn.MaxPool2d(2)\n",
    "        self.pool2 = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "        n_sizes = self._get_conv_output(input_shape)\n",
    "\n",
    "        self.fc1 = nn.Linear(n_sizes, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    # returns the size of the output tensor going into Linear layer from the conv block.\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self._forward_features(input) \n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "        \n",
    "    # returns the feature tensor from the conv block\n",
    "    def _forward_features(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        return x\n",
    "    \n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "       x = self._forward_features(x)\n",
    "       x = x.view(x.size(0), -1)\n",
    "       x = F.relu(self.fc1(x))\n",
    "       x = F.relu(self.fc2(x))\n",
    "       x = F.log_softmax(self.fc3(x), dim=1)\n",
    "       \n",
    "       return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # training metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = CIFAR10DataModule(batch_size=32)\n",
    "# To access the x_dataloader we need to call prepare_data and setup.\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "# Samples required by the custom ImagePredictionLogger callback to log image predictions.\n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "model = LitModel((3, 32, 32), dm.num_classes)\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')\n",
    "\n",
    "# Initialize logger\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs/\")\n",
    "\n",
    "# Initialize Callbacks\n",
    "early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint()\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(max_epochs=10,\n",
    "                     gpus=0, \n",
    "                     logger=tb_logger,\n",
    "                     callbacks=[early_stop_callback,\n",
    "                                ImagePredictionLogger(val_samples),\n",
    "                                checkpoint_callback],\n",
    "                     )\n",
    "\n",
    "# Train the model ⚡🚅⚡\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# Evaluate the model on the held-out test set ⚡⚡\n",
    "trainer.test(dataloaders=dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd9300a6f4ece537b026f5555e1cfb0290f34cb2144f98800c9536eaf54c0e3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
