{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Package ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch<1.9,>=1.6 (from versions: 1.9.0, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch<1.9,>=1.6\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from pytorch-lightning) (4.3.0)\n",
      "Requirement already satisfied: torch>=1.9.* in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from pytorch-lightning) (1.12.1)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Using cached fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from pytorch-lightning) (1.23.3)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
      "Collecting PyYAML>=5.4\n",
      "  Using cached PyYAML-6.0.tar.gz (124 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.3-cp38-cp38-macosx_11_0_arm64.whl (337 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.36.2)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.5-py2.py3-none-any.whl (162 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.11.1-py2.py3-none-any.whl (167 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (57.0.0)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.49.1.tar.gz (22.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp38-cp38-macosx_11_0_arm64.whl (35 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp38-cp38-macosx_11_0_arm64.whl (57 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting attrs>=17.3.0\n",
      "  Using cached attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/joonhwi/Desktop/KAU/4-2/capstone/crack_segmentaion/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.1-cp38-cp38-macosx_10_9_universal2.whl (17 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: PyYAML, grpcio\n",
      "  Building wheel for PyYAML (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-6.0-cp38-cp38-macosx_10_14_arm64.whl size=45338 sha256=928c54c08cec6063f2f3b6a173fb1ea0b53b410eec1a558501dc0e58d613d07a\n",
      "  Stored in directory: /Users/joonhwi/Library/Caches/pip/wheels/52/84/66/50912fd7bf1639a31758e40bd4312602e104a8eca1e0da9645\n",
      "  Building wheel for grpcio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpcio: filename=grpcio-1.49.1-cp38-cp38-macosx_10_14_arm64.whl size=7903788 sha256=b09f4efa7ec1e359ee9ae7e5577e4539b2f8281bfe3b2b8026dc389c3159d88c\n",
      "  Stored in directory: /Users/joonhwi/Library/Caches/pip/wheels/ae/75/9b/1cfee21306a9993817964b0c777cbedf8a42342254986cd0e9\n",
      "Successfully built PyYAML grpcio\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, zipp, urllib3, tqdm, tensorboard-data-server, rsa, PyYAML, pyDeprecate, pyasn1-modules, protobuf, oauthlib, multidict, MarkupSafe, idna, grpcio, fsspec, frozenlist, charset-normalizer, certifi, cachetools, attrs, async-timeout, absl-py, yarl, werkzeug, torchmetrics, requests, importlib-metadata, google-auth, aiosignal, requests-oauthlib, markdown, aiohttp, google-auth-oauthlib, tensorboard, pytorch-lightning\n",
      "Successfully installed MarkupSafe-2.1.1 PyYAML-6.0 absl-py-1.2.0 aiohttp-3.8.3 aiosignal-1.2.0 async-timeout-4.0.2 attrs-22.1.0 cachetools-5.2.0 certifi-2022.9.24 charset-normalizer-2.1.1 frozenlist-1.3.1 fsspec-2022.8.2 google-auth-2.11.1 google-auth-oauthlib-0.4.6 grpcio-1.49.1 idna-3.4 importlib-metadata-4.12.0 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.1 protobuf-3.19.5 pyDeprecate-0.3.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-1.7.7 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torchmetrics-0.9.3 tqdm-4.64.1 urllib3-1.26.12 werkzeug-2.2.2 yarl-1.8.1 zipp-3.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet \"pandas\" \"torch>=1.6, <1.9\" \"torchvision\" \"ipython[notebook]\" \"seaborn\" \"pytorch-lightning>=1.4\" \"torchmetrics>=0.6\" \"lightning-bolts\"\n",
    "! pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install seaborn\n",
    "#! pip install torchvision\n",
    "#! pip install lightning-bolts\n",
    "#! pip install pytorch_lightning\n",
    "# install pytorch lighting\n",
    "! pip install pytorch-lightning --quiet\n",
    "# install weights and biases\n",
    "! pip install wandb --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pytorch_lightning as pl\n",
    "# your favorite machine learning tracking tool\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ë°ì´í„° ëª¨ë“ˆ ì •ì˜í•˜ê¸°\n",
    "\n",
    "cifar 10 ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "cifar 10 ë°ì´í„° ì…‹ì€ LightningDataModuleì˜ ì„œë¸Œí´ë˜ìŠ¤ì´ë¯€ë¡œ, ìƒì†ë°›ì•„ ë©”ì„œë“œë¥¼ êµ¬í˜„í•œë‹¤.\n",
    "\n",
    "ê³µì‹ doc ì°¸ê³ í•˜ê¸° : https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html\n",
    "\n",
    "### ë©”ì„œë“œ ê°„ëµ ì„¤ëª…\n",
    "    prepare_data\n",
    "GPU í•˜ë‚˜ì—ì„œ í•œ ë²ˆë§Œ í˜¸ì¶œëœë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì•„ë˜ì˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë‹¨ê³„ì™€ ê°™ë‹¤.\n",
    "\n",
    "    setup\n",
    "ê°ê°ì˜ GPUì—ì„œ ê°œë³„ì ìœ¼ë¡œ í˜¸ì¶œë˜ë©° fit ë˜ëŠ” testë‹¨ê³„ì¼ ê²½ìš° ì •ì˜í•  ìŠ¤í…Œì´ì§€ë¥¼ ë°›ì•„ì˜¨ë‹¤.\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader\n",
    "ê°ê°ì˜ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë“œí•œë‹¤.\n",
    "\n",
    "### Notes\n",
    "- random_split : training-validation splitêµ¬ë¶„ì„ ìš©ì´í•˜ê²Œ í•œë‹¤. ì „ì²´ ë°ì´í„°ì…‹ì— ì ìš©ëœë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, data_dir: str = './'):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            #í…ì„œí™” ë° ì •ê·œí™”\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ìˆ˜ ì •ì˜\n",
    "        self.num_classes = 10\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            #cifar ë°ì´í„° ë°›ì•„ì™€ì„œ ê²½ë¡œ, transform, train, ë“±ë“± ì„¤ì •í•˜ê¸° \n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logger ì •ì˜í•˜ê¸°\n",
    "\n",
    "epochì´ ëë‚  ë•Œë§ˆë‹¤ ì„±ëŠ¥ ë¡œê·¸ë¥¼ ë‚¨ê¸´ë‹¤. \n",
    "\n",
    "## Notes\n",
    "    pytorch_lightning.callbacks.Callback\n",
    "\n",
    "ê³µì‹ docs ë³´ê¸° : https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html\n",
    "\n",
    "í”„ë¡œì íŠ¸ ì „ì²´ì—ì„œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë…ë¦½í˜• í”„ë¡œê·¸ë¨ì„ ëœ»í•œë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, í•™ìŠµì¤‘\n",
    "\n",
    "    on_validation_epoch_end\n",
    "\n",
    "ë©”ì„œë“œê°€ ìˆ˜í–‰ë˜ë©´ callback hook ì´ ìˆ˜í–‰ë˜ì–´ ì•„ë˜ì˜ ì½”ë“œê°€ ìˆ˜í–‰ëœë‹¤.\n",
    "\n",
    "ë‹¤ì‹œë§í•´ validation epochì´ ì¢…ë£Œë  ë•Œ, ë¡œê·¸ë¥¼ ë‚¨ê¸°ëŠ” ì½”ë“œê°€ ìˆ˜í–‰ë˜ëŠ” ê²ƒì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePredictionLogger(pl.callbacks.Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Bring the tensors to CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Get model prediction\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ëª¨ë¸ ì •ì˜í•˜ê¸°\n",
    "\n",
    "LightningModuleì€ ëª¨ë¸ì´ ì•„ë‹Œ ì‹œìŠ¤í…œì„ ì •ì˜í•˜ê¸° ë•Œë¬¸ì—, ëª¨ë¸ì„ ë‹¨ì¼ í´ë˜ìŠ¤ë¡œ ë…ë¦½í™”ì‹œì¼œì•¼í•œë‹¤.\n",
    "\n",
    "ê¸°ì¡´ì˜ Pytorch ì½”ë“œë¥¼ 5ê°œì˜ ì„¹ì…˜ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë„£ì–´ì£¼ë©´ ëœë‹¤.\n",
    "- Computations (__init__).\n",
    "\n",
    "- Train loop (training_step)\n",
    "\n",
    "- Validation loop (validation_step)\n",
    "\n",
    "- Test loop (test_step)\n",
    "\n",
    "- Optimizers (configure_optimizers)\n",
    "\n",
    "### ë©”ì„œë“œ ê°„ëµ ì„¤ëª…\n",
    "pytorch_lightning.LightningModuleì€ ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ì™€ forward ì „ë‹¬ ë°©ì‹ì„ ìƒì†ë°›ì•„ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ í•´ë†¨ë‹¤.\n",
    "\n",
    "#### 1. init ë©”ì„œë“œ\n",
    "\n",
    "initì—ì„œ ëª¨ë¸ì— í•„ìš”í•œ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•œë‹¤.\n",
    "\n",
    "    save_parameters\n",
    "\n",
    "ë¥¼ call í•¨ìœ¼ë¡œì¨ initì— ìˆëŠ” ëª¨ë“  ê°’ì„ check pointì— ì €ì¥í•˜ë„ë¡ ìš”ì²­í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    ". . .\n",
    "\n",
    "\n",
    "    _get_conv_outputê³¼ _forward_features\n",
    "\n",
    "ë©”ì„œë“œëŠ” convolutional blockì˜ í…ì„œ ì‚¬ì´ì¦ˆë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•˜ëŠ”ë° ì‚¬ìš©í•œë‹¤. \n",
    "\n",
    ". . .\n",
    "\n",
    "    forward\n",
    "ì¼ë‹¨ íŒŒì´í† ì¹˜ ì½”ë“œì™€ ë¹„ìŠ·í•˜ë‚˜, ë¼ì´íŠ¸ë‹ì—ì„œëŠ” ì˜¤ì§ inference actionì„ ìœ„í•´ì„œë§Œ ì‚¬ìš©ëœë‹¤. training_stepì€ í•™ìŠµ loopë¥¼ ì •ì˜í•œë‹¤.\n",
    "\n",
    "\n",
    "#### 2. Training step ë©”ì„œë“œ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, input_shape, num_classes, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 1)\n",
    "\n",
    "        self.pool1 = torch.nn.MaxPool2d(2)\n",
    "        self.pool2 = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "        n_sizes = self._get_conv_output(input_shape)\n",
    "\n",
    "        self.fc1 = nn.Linear(n_sizes, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    # returns the size of the output tensor going into Linear layer from the conv block.\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self._forward_features(input) \n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "        \n",
    "    # returns the feature tensor from the conv block\n",
    "    def _forward_features(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        return x\n",
    "    \n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "       x = self._forward_features(x)\n",
    "       x = x.view(x.size(0), -1)\n",
    "       x = F.relu(self.fc1(x))\n",
    "       x = F.relu(self.fc2(x))\n",
    "       x = F.log_softmax(self.fc3(x), dim=1)\n",
    "       \n",
    "       return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # training metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = CIFAR10DataModule(batch_size=32)\n",
    "# To access the x_dataloader we need to call prepare_data and setup.\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "# Samples required by the custom ImagePredictionLogger callback to log image predictions.\n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "model = LitModel((3, 32, 32), dm.num_classes)\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')\n",
    "\n",
    "# Initialize logger\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs/\")\n",
    "\n",
    "# Initialize Callbacks\n",
    "early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint()\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(max_epochs=10,\n",
    "                     gpus=0, \n",
    "                     logger=tb_logger,\n",
    "                     callbacks=[early_stop_callback,\n",
    "                                ImagePredictionLogger(val_samples),\n",
    "                                checkpoint_callback],\n",
    "                     )\n",
    "\n",
    "# Train the model âš¡ğŸš…âš¡\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# Evaluate the model on the held-out test set âš¡âš¡\n",
    "trainer.test(dataloaders=dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd9300a6f4ece537b026f5555e1cfb0290f34cb2144f98800c9536eaf54c0e3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
